import json
import re
import traceback as tb
from typing import Any, Optional, List, Tuple

from core.agent import Agent
from core.llm import HelloAgentsLLM
from core.message import Message
from core.config import Config
from core.context_builder import ContextBuilder
from core.trace_logger import create_trace_logger
from core.history_manager import HistoryManager
from core.input_preprocessor import preprocess_input
from core.summary_compressor import create_summary_generator
from tools.registry import ToolRegistry
from tools.builtin.list_files import ListFilesTool
from tools.builtin.search_files_by_name import SearchFilesByNameTool
from tools.builtin.search_code import GrepTool
from tools.builtin.read_file import ReadTool
from tools.builtin.write_file import WriteTool
from tools.builtin.edit_file import EditTool
from tools.builtin.edit_file_multi import MultiEditTool
from tools.builtin.todo_write import TodoWriteTool
from tools.builtin.bash import BashTool
from utils import setup_logger


class CodeAgent(Agent):
    """
    Code Agent - åŸºäº ReAct çš„ä»£ç åŠ©æ‰‹
    
    ä¸Šä¸‹æ–‡å·¥ç¨‹æ”¹é€ ï¼ˆæŒ‰æ–¹æ¡ˆ D3ï¼‰ï¼š
    - ä½¿ç”¨ HistoryManager ç®¡ç†ä¼šè¯å†å²
    - ReAct æ¯ä¸€æ­¥åŒæ­¥å†™å…¥ assistant/tool æ¶ˆæ¯åˆ° history
    - æ”¯æŒå‹ç¼©è§¦å‘å’Œ Summary ç”Ÿæˆ
    """
    
    def __init__(
        self, 
        name: str, 
        llm: HelloAgentsLLM, 
        tool_registry: ToolRegistry,
        project_root: str,
        system_prompt: Optional[str] = None,
        config: Optional[Config] = None,
        logger=None,
    ):
        super().__init__(name, llm, system_prompt=system_prompt, config=config)
        self.project_root = project_root
        self.tool_registry = tool_registry
        self.logger = logger or setup_logger(
            name=f"agent.{self.name}",
            level=self.config.log_level,
        )
        self.last_response_raw: Optional[Any] = None
        self.max_steps = 50
        self.verbose = True
        
        # åˆ›å»º Summary ç”Ÿæˆå™¨ï¼ˆPhase 7ï¼‰
        summary_generator = create_summary_generator(
            llm=self.llm,
            config=self.config,
            verbose=self.verbose,
        )
        
        # å†å²ç®¡ç†å™¨ï¼ˆæ›¿ä»£ Agent._historyï¼‰
        self.history_manager = HistoryManager(
            config=self.config,
            summary_generator=summary_generator,
        )
        
        # æ³¨å†Œå·¥å…·
        self._register_builtin_tools()
        
        # ä¸Šä¸‹æ–‡æ„å»ºå™¨
        self.context_builder = ContextBuilder(
            tool_registry=self.tool_registry,
            project_root=self.project_root,
            system_prompt_override=self.system_prompt,
        )

        # Trace æ—¥å¿—ï¼ˆå•å®ä¾‹è´¯ç©¿ Agent ç”Ÿå‘½å‘¨æœŸï¼‰
        self.trace_logger = create_trace_logger()
        self._system_messages_logged = False
        self._run_id = 0
    
    def _register_builtin_tools(self):
        """æ³¨å†Œå†…ç½®å·¥å…·"""
        self.tool_registry.register_tool(
            ListFilesTool(project_root=self.project_root, working_dir=self.project_root)
        )
        self.tool_registry.register_tool(SearchFilesByNameTool(project_root=self.project_root))
        self.tool_registry.register_tool(GrepTool(project_root=self.project_root))
        self.tool_registry.register_tool(ReadTool(project_root=self.project_root))
        self.tool_registry.register_tool(WriteTool(project_root=self.project_root))
        self.tool_registry.register_tool(EditTool(project_root=self.project_root))
        self.tool_registry.register_tool(MultiEditTool(project_root=self.project_root))
        self.tool_registry.register_tool(TodoWriteTool(project_root=self.project_root))
        self.tool_registry.register_tool(BashTool(project_root=self.project_root))

    def run(self, input_text: str, **kwargs) -> str:
        """
        Code Agent çš„å…¥å£ï¼ˆMessage List è‡ªç„¶ç´¯ç§¯æ¨¡å¼ï¼‰
        
        æµç¨‹ï¼š
        1. é¢„å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆ@file è§£æï¼‰
        2. æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©å†å²
        3. å°†ç”¨æˆ·æ¶ˆæ¯å†™å…¥ historyï¼ˆè½®æ¬¡å¼€å§‹ï¼‰
        4. è¿è¡Œ ReAct å¾ªç¯ï¼ˆæ¯æ­¥ assistant/tool æ¶ˆæ¯è‡ªç„¶ç´¯ç§¯ï¼‰
        5. è¿”å›æœ€ç»ˆç»“æœ
        
        Message List æ¨¡å¼ï¼š
        - ä¸å†ä½¿ç”¨ scratchpad æ‹¼æ¥
        - æ¯æ­¥çš„ messages ç”± history è‡ªç„¶ç´¯ç§¯
        - L1/L2 ä½œä¸º system messages
        - L3 æ˜¯ç´¯ç§¯çš„ user/assistant/tool
        """
        show_raw = kwargs.pop("show_raw", False)
        if not show_raw:
            self.last_response_raw = None

        # 1. é¢„å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆ@file è§£æï¼‰
        preprocess_result = preprocess_input(input_text)
        processed_input = preprocess_result.processed_input
        
        if preprocess_result.mentioned_files and self.verbose:
            print(f"\nğŸ“ æ£€æµ‹åˆ°æ–‡ä»¶å¼•ç”¨: {', '.join(preprocess_result.mentioned_files)}")
            if preprocess_result.truncated_count > 0:
                print(f"   (å¦æœ‰ {preprocess_result.truncated_count} ä¸ªæ–‡ä»¶è¢«çœç•¥)")

        trace_logger = self.trace_logger
        self._run_id += 1
        run_id = self._run_id

        self._log_system_messages_if_needed(trace_logger)
        trace_logger.log_event(
            "run_start",
            {
                "run_id": run_id,
                "input": input_text,
                "processed": processed_input,
            },
            step=0,
        )
        
        # 2. æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©ï¼ˆA6 è§„åˆ™ï¼‰
        if self.history_manager.should_compress(processed_input):
            estimated_tokens = self.history_manager._last_usage_tokens + len(processed_input) // 3
            threshold = int(self.config.context_window * self.config.compression_threshold)
            trace_logger.log_event("history_compression_triggered", {
                "estimated_tokens": estimated_tokens,
                "threshold": threshold,
                "message_count": self.history_manager.get_message_count(),
            }, step=0)
            
            if self.verbose:
                print("\nğŸ“¦ è§¦å‘å†å²å‹ç¼©...")
            
            rounds_before = self.history_manager.get_rounds_count()
            messages_before = self.history_manager.get_message_count()
            
            compress_info = self.history_manager.compact(
                on_event=lambda ev, payload: trace_logger.log_event(ev, payload, step=0),
                return_info=True,
            )
            compressed = bool(compress_info.get("compressed"))
            
            if compressed:
                rounds_after = self.history_manager.get_rounds_count()
                messages_after = self.history_manager.get_message_count()
                
                trace_logger.log_event("history_compression_completed", {
                    "rounds_before": rounds_before,
                    "rounds_after": rounds_after,
                    "messages_compressed": messages_before - messages_after,
                    "summary_generated": compress_info.get("summary_generated", False),
                    "details": compress_info,
                }, step=0)

                # è®°å½•å‹ç¼©åçš„æœ€ç»ˆä¸Šä¸‹æ–‡ï¼ˆsystem + historyï¼‰
                compressed_history = self.history_manager.to_messages()
                final_context = self.context_builder.build_messages(compressed_history)
                trace_logger.log_event(
                    "history_compression_final_context",
                    {"message_count": len(final_context), "messages": final_context},
                    step=0,
                )
                
                if self.verbose:
                    print(f"âœ… å‹ç¼©å®Œæˆï¼Œå½“å‰è½®æ¬¡æ•°: {rounds_after}")
                    self._print_context_preview(final_context)

        # 3. å°†ç”¨æˆ·æ¶ˆæ¯å†™å…¥ historyï¼ˆè½®æ¬¡å¼€å§‹æ—¶å†™å…¥ï¼‰
        self.history_manager.append_user(processed_input)
        trace_logger.log_event("user_input", {"text": input_text, "processed": processed_input}, step=0)
        self._log_message_write(trace_logger, "user", processed_input, {}, step=0)

        if self.verbose:
            print(f"\nâš™ï¸ Engine å¯åŠ¨: {input_text}")

        response_text = ""
        try:
            response_text = self._react_loop(
                show_raw=show_raw,
                trace_logger=trace_logger,
            )
        finally:
            trace_logger.log_event(
                "run_end",
                {"run_id": run_id, "final": response_text if "response_text" in locals() else ""},
                step=0,
            )

        self.logger.debug("response=%s", response_text)
        self.logger.info("history_size=%d, rounds=%d", 
                        self.history_manager.get_message_count(),
                        self.history_manager.get_rounds_count())
        return response_text

    def close(self):
        """å…³é—­ Agent å¹¶å†™å…¥ trace æ€»ç»“"""
        if self.trace_logger:
            self.trace_logger.finalize()
            self.trace_logger = None

    # =========================================================================
    # ReAct Coreï¼ˆMessage List è‡ªç„¶ç´¯ç§¯æ¨¡å¼ï¼‰
    # =========================================================================

    def _react_loop(
        self,
        show_raw: bool,
        trace_logger,
    ) -> str:
        """
        ReAct å¾ªç¯ï¼ˆMessage List æ¨¡å¼ï¼‰
        
        æ¯æ­¥ï¼š
        1. æ„å»º messages = system(L1/L2) + history(user/assistant/tool)
        2. è°ƒç”¨ LLM
        3. è§£æ Thought/Action
        4. è‹¥ä¸º Finishï¼šè¿”å›ç»“æœ
        5. è‹¥ä¸ºå·¥å…·è°ƒç”¨ï¼šæ‰§è¡Œå·¥å…·ï¼Œå°† assistant + tool æ¶ˆæ¯è¿½åŠ åˆ° history
        """
        for step in range(1, self.max_steps + 1):
            if self.verbose:
                print(f"\n--- Step {step}/{self.max_steps} ---")

            # æ„å»º messages åˆ—è¡¨
            history_messages = self.history_manager.to_messages()
            messages = self.context_builder.build_messages(history_messages)
            base_messages = messages
            
            trace_logger.log_event(
                "context_build",
                {"message_count": len(messages), "history_count": len(history_messages)},
                step=step,
            )

            usage = None
            empty_retry_used = False
            response_text = ""

            while True:
                # è°ƒç”¨ LLM
                raw_response = self.llm.invoke_raw(messages)
                if show_raw:
                    self.last_response_raw = (
                        raw_response.model_dump()
                        if hasattr(raw_response, "model_dump")
                        else raw_response
                    )

                response_text = self._extract_content(raw_response)
                usage = self._extract_usage(raw_response)
                if usage and usage.get("total_tokens") is not None:
                    self.history_manager.update_last_usage(usage["total_tokens"])

                response_meta = self._extract_response_meta(raw_response)
                raw_dump = self._extract_raw_response(raw_response)
                trace_logger.log_event(
                    "model_output",
                    {"raw": response_text, "usage": usage, "meta": response_meta, "raw_response": raw_dump},
                    step=step,
                )

                if response_text and str(response_text).strip():
                    break

                # å·¥å…·/å‡½æ•°è°ƒç”¨æ¢å¤
                recovered_text, recover_meta = self._recover_empty_response(raw_response)
                if recovered_text:
                    response_text = recovered_text
                    trace_logger.log_event(
                        "empty_response_recovered",
                        {"source": recover_meta.get("source"), "details": recover_meta},
                        step=step,
                    )
                    break

                # é‡è¯•ä¸€æ¬¡å¹¶è¿½åŠ æç¤º
                if not empty_retry_used:
                    empty_retry_used = True
                    hint = "ä¸Šæ¬¡ content ä¸ºç©ºï¼Œè¯·åŠ¡å¿…åœ¨ content è¾“å‡º Thought/Action æˆ– Finish"
                    messages = base_messages + [{"role": "system", "content": hint}]
                    trace_logger.log_event(
                        "empty_response_retry",
                        {
                            "finish_reason": response_meta.get("finish_reason"),
                            "content_len": response_meta.get("content_len"),
                            "reasoning_len": response_meta.get("reasoning_len"),
                            "hint": hint,
                        },
                        step=step,
                    )
                    if self.verbose:
                        print("âš ï¸ LLMè¿”å›ç©ºå“åº”ï¼Œè¿½åŠ æç¤ºåé‡è¯•ä¸€æ¬¡")
                    continue

                if self.verbose:
                    print("âŒ LLMè¿”å›ç©ºå“åº”")
                trace_logger.log_event(
                    "error",
                    {
                        "stage": "llm_response",
                        "error_code": "INTERNAL_ERROR",
                        "message": "Empty response",
                        "meta": response_meta,
                    },
                    step=step,
                )
                break

            if not response_text or not str(response_text).strip():
                break

            thought, action = self._parse_thought_action(str(response_text))

            if self.verbose and thought:
                print(f"\nğŸ¤” Thought:\n{thought}\n")

            # å¤„ç†æ—  Action çš„æƒ…å†µ
            if not action:
                finish_payload = self._extract_finish_direct(str(response_text))
                if finish_payload is not None:
                    # Finish è·¯å¾„ï¼šä»…è®°å½•æœ€ç»ˆå›ç­”å†…å®¹
                    assistant_content = finish_payload
                    self.history_manager.append_assistant(
                        content=assistant_content,
                        metadata={"step": step, "action_type": "finish"},
                    )
                    self._log_message_write(trace_logger, "assistant", assistant_content, {"action_type": "finish"}, step)
                    if self.verbose:
                        print("\nâœ… Finish\n")
                    trace_logger.log_event(
                        "parsed_action",
                        {"thought": thought or "", "action": "Finish", "args": {"payload": finish_payload}},
                        step=step,
                    )
                    trace_logger.log_event("finish", {"final": finish_payload}, step=step)
                    return finish_payload
                
                # æ—  Actionï¼šæŒ‰æ™®é€šå¯¹è¯è®°å½•åŸå§‹å›å¤å¹¶ç»“æŸ
                assistant_content = str(response_text).strip()
                self.history_manager.append_assistant(
                    content=assistant_content,
                    metadata={"step": step, "action_type": "no_action"},
                )
                self._log_message_write(trace_logger, "assistant", assistant_content, {"action_type": "no_action"}, step)
                return assistant_content

            # å¤„ç† Finish Action
            if action.strip().startswith("Finish["):
                final_answer = self._parse_bracket_payload(action)
                assistant_content = final_answer
                self.history_manager.append_assistant(
                    content=assistant_content,
                    metadata={"step": step, "action_type": "finish"},
                )
                self._log_message_write(trace_logger, "assistant", assistant_content, {"action_type": "finish"}, step)
                
                if self.verbose:
                    print("\nâœ… Finish\n")
                trace_logger.log_event(
                    "parsed_action",
                    {"thought": thought or "", "action": "Finish", "args": {"payload": final_answer}},
                    step=step,
                )
                trace_logger.log_event("finish", {"final": final_answer}, step=step)
                return final_answer

            # è§£æå·¥å…·è°ƒç”¨
            tool_name, tool_raw_input = self._parse_tool_call(action)
            if not tool_name:
                assistant_content = f"Thought: {thought or ''}\nAction: {action}\n(Invalid action format)"
                self.history_manager.append_assistant(content=assistant_content, metadata={"step": step, "action_type": "invalid_action"})
                self._log_message_write(trace_logger, "assistant", assistant_content, {"action_type": "invalid_action"}, step)
                continue

            tool_input, parse_err = self._ensure_json_input(tool_raw_input)
            trace_logger.log_event("parsed_action", {"thought": thought or "", "action": action, "args": tool_input if parse_err is None else {"raw": tool_raw_input}}, step=step)
            
            if parse_err:
                assistant_content = f"Thought: {thought or ''}\nAction: {tool_name}[{tool_raw_input}]\n(Parameter parse error: {parse_err})"
                self.history_manager.append_assistant(content=assistant_content, metadata={"step": step, "action_type": "parse_error", "tool_name": tool_name})
                self._log_message_write(trace_logger, "assistant", assistant_content, {"action_type": "parse_error"}, step)
                continue

            trace_logger.log_event("tool_call", {"tool": tool_name, "args": tool_input}, step=step)

            if self.verbose:
                print(f"\nğŸ¬ Action: {tool_name}[{tool_input}]\n")

            # å†™å…¥ assistant æ¶ˆæ¯ï¼ˆThought + Actionï¼‰
            assistant_content = f"Thought: {thought or ''}\nAction: {tool_name}[{json.dumps(tool_input, ensure_ascii=False)}]"
            self.history_manager.append_assistant(content=assistant_content, metadata={"step": step, "action_type": "tool_call", "tool_name": tool_name})
            self._log_message_write(trace_logger, "assistant", assistant_content, {"action_type": "tool_call", "tool_name": tool_name}, step)

            # æ‰§è¡Œå·¥å…·
            try:
                observation = self._execute_tool(tool_name, tool_input)
                try:
                    result_obj = json.loads(observation)
                    trace_logger.log_event("tool_result", {"tool": tool_name, "result": result_obj}, step=step)
                except json.JSONDecodeError:
                    trace_logger.log_event("tool_result", {"tool": tool_name, "result": {"text": observation}}, step=step)
            except Exception as e:
                error_result = {"status": "error", "error": {"code": "EXECUTION_ERROR", "message": str(e)}, "data": {}}
                observation = json.dumps(error_result, ensure_ascii=False)
                trace_logger.log_event("error", {"stage": "tool_execution", "error_code": "EXECUTION_ERROR", "message": str(e), "tool": tool_name, "traceback": tb.format_exc()}, step=step)

            # å†™å…¥ tool æ¶ˆæ¯åˆ° historyï¼ˆå‹ç¼©ç‰ˆï¼‰
            self.history_manager.append_tool(tool_name=tool_name, raw_result=observation, metadata={"step": step})
            self._log_message_write(trace_logger, "tool", observation, {"tool_name": tool_name}, step)

            if self.verbose:
                display_obs = observation[:300] + "..." if len(observation) > 300 else observation
                print(f"\nğŸ‘€ Observation: {display_obs}\n")

        return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•åœ¨é™å®šæ­¥æ•°å†…å®Œæˆè¿™ä¸ªä»»åŠ¡ã€‚"

    # =========================================================================
    # è¾…åŠ©æ–¹æ³•
    # =========================================================================
    
    def _log_message_write(self, trace_logger, role: str, content: str, metadata: dict, step: int = 0):
        """è¾…åŠ©ï¼šè®°å½•æ¶ˆæ¯å†™å…¥åˆ° trace"""
        trace_logger.log_event("message_written", {
            "role": role,
            "content": content,
            "metadata": metadata,
        }, step=step)

    def _log_system_messages_if_needed(self, trace_logger) -> None:
        if self._system_messages_logged or not trace_logger:
            return
        system_messages = self.context_builder.get_system_messages()
        trace_logger.log_system_messages(system_messages)
        self._system_messages_logged = True

    def _print_context_preview(
        self,
        messages: list[dict],
        max_messages: int = 10,
        content_limit: int = 200,
    ) -> None:
        if not messages:
            print("ï¼ˆå½“å‰ä¸Šä¸‹æ–‡ä¸ºç©ºï¼‰")
            return
        total = len(messages)
        preview = messages[:max_messages]
        print("\nğŸ“Œ å½“å‰ä¸Šä¸‹æ–‡ï¼ˆæœ€å¤šæ˜¾ç¤º 10 æ¡ï¼‰")
        for msg in preview:
            role = msg.get("role", "unknown")
            content = msg.get("content", "")
            content = str(content).replace("\n", "\\n")
            if len(content) > content_limit:
                content = content[:content_limit] + "...(truncated)"
            print(f'message({role}, "{content}")')
        if total > max_messages:
            print(f"...ï¼ˆå…¶ä½™ {total - max_messages} æ¡å·²çœç•¥ï¼‰")

    def _execute_tool(self, tool_name: str, tool_input: Any) -> str:
        res = self.tool_registry.execute_tool(tool_name, tool_input)
        return str(res)

    def _parse_thought_action(self, text: str) -> Tuple[Optional[str], Optional[str]]:
        action_spans = list(re.finditer(r"^Action:\s*", text, flags=re.MULTILINE))
        if not action_spans:
            return self._extract_last_block(text, "Thought"), None
        last_action = action_spans[-1]
        action_content = text[last_action.end():].strip()
        action_line = action_content if action_content else None
        prefix = text[: last_action.start()]
        thought = self._extract_last_block(prefix, "Thought")
        return thought, action_line

    def _extract_last_block(self, text: str, tag: str) -> Optional[str]:
        spans = list(re.finditer(rf"^{re.escape(tag)}:\s*", text, flags=re.MULTILINE))
        if not spans:
            return None
        last = spans[-1]
        content = text[last.end():].strip()
        return content if content else None

    def _extract_finish_direct(self, text: str) -> Optional[str]:
        matches = list(re.finditer(r"^Finish\[(.*)\]\s*$", text, flags=re.MULTILINE | re.DOTALL))
        if not matches:
            return None
        payload = matches[-1].group(1).strip()
        return payload if payload else ""

    def _parse_tool_call(self, action: str) -> Tuple[Optional[str], str]:
        m = re.match(r"^([A-Za-z0-9_\-]+)\[(.*)\]\s*$", action.strip(), flags=re.DOTALL)
        if not m:
            return None, ""
        return m.group(1), m.group(2).strip()

    def _parse_bracket_payload(self, action: str) -> str:
        m = re.match(r"^[A-Za-z0-9_\-]+\[(.*)\]\s*$", action.strip(), flags=re.DOTALL)
        return (m.group(1).strip() if m else "").strip()

    def _ensure_json_input(self, raw: str) -> Tuple[Any, Optional[str]]:
        if raw is None:
            return {}, None
        s = str(raw).strip()
        if not s:
            return {}, None
        try:
            return json.loads(s), None
        except Exception as e:
            return None, str(e)

    @staticmethod
    def _extract_content(raw_response: Any) -> Optional[str]:
        try:
            if hasattr(raw_response, "choices"):
                return raw_response.choices[0].message.content
            if isinstance(raw_response, dict) and raw_response.get("choices"):
                return raw_response["choices"][0]["message"].get("content")
        except Exception:
            return str(raw_response)

    @staticmethod
    def _extract_usage(raw_response: Any) -> Optional[dict]:
        try:
            if hasattr(raw_response, "usage"):
                usage = raw_response.usage
                if not usage:
                    return None
                return {
                    "prompt_tokens": getattr(usage, "prompt_tokens", None),
                    "completion_tokens": getattr(usage, "completion_tokens", None),
                    "total_tokens": getattr(usage, "total_tokens", None),
                }
            if isinstance(raw_response, dict) and raw_response.get("usage"):
                usage = raw_response["usage"]
                return {
                    "prompt_tokens": usage.get("prompt_tokens"),
                    "completion_tokens": usage.get("completion_tokens"),
                    "total_tokens": usage.get("total_tokens"),
                }
        except Exception:
            return None

    @staticmethod
    def _recover_empty_response(raw_response: Any) -> Tuple[Optional[str], Optional[dict]]:
        """
        å°è¯•ä»ç©ºå“åº”ä¸­æ¢å¤ï¼š
        - æ”¯æŒ OpenAI function_call/tool_calls è¿”å›ä½† content ä¸ºç©ºçš„åœºæ™¯
        - è¿”å› (recovered_text, meta)ï¼›è‹¥æ— æ³•æ¢å¤åˆ™è¿”å› (None, None)
        """
        def _get_attr(obj, key: str):
            if obj is None:
                return None
            if isinstance(obj, dict):
                return obj.get(key)
            return getattr(obj, key, None)

        try:
            choices = _get_attr(raw_response, "choices")
            if not choices:
                return None, None
            choice = choices[0]
            message = _get_attr(choice, "message")
            if not message:
                return None, None

            tool_calls = _get_attr(message, "tool_calls") or []
            if tool_calls:
                call = tool_calls[0]
                fn = _get_attr(call, "function") or {}
                name = _get_attr(fn, "name") or "unknown_tool"
                arguments = _get_attr(fn, "arguments") or ""
                args_str = arguments if isinstance(arguments, str) else json.dumps(arguments, ensure_ascii=False)
                return f"Action: {name}[{args_str}]", {"source": "tool_call", "tool": name}

            function_call = _get_attr(message, "function_call")
            if function_call:
                name = _get_attr(function_call, "name") or "unknown_function"
                arguments = _get_attr(function_call, "arguments") or ""
                args_str = arguments if isinstance(arguments, str) else json.dumps(arguments, ensure_ascii=False)
                return f"Action: {name}[{args_str}]", {"source": "function_call", "tool": name}

            content = _get_attr(message, "content")
            if content and str(content).strip():
                return str(content), {"source": "content"}
        except Exception:
            return None, None

        return None, None


    @staticmethod
    def _extract_response_meta(raw_response: Any) -> dict:
        """æå–å“åº”å…ƒä¿¡æ¯ï¼Œè¾…åŠ©å®šä½ç©ºå“åº”åŸå› """
        def _get_attr(obj, key: str):
            if obj is None:
                return None
            if isinstance(obj, dict):
                return obj.get(key)
            return getattr(obj, key, None)

        meta: dict = {}
        try:
            choices = _get_attr(raw_response, "choices") or []
            if not choices:
                return meta
            choice = choices[0]
            meta["finish_reason"] = _get_attr(choice, "finish_reason")
            message = _get_attr(choice, "message")
            if not message:
                return meta
            meta["role"] = _get_attr(message, "role")

            content = _get_attr(message, "content")
            reasoning_content = _get_attr(message, "reasoning_content") or _get_attr(message, "reasoning")
            refusal = _get_attr(message, "refusal")
            tool_calls = _get_attr(message, "tool_calls")
            function_call = _get_attr(message, "function_call")

            meta["content_len"] = len(str(content)) if content is not None else 0
            meta["reasoning_len"] = len(str(reasoning_content)) if reasoning_content is not None else 0
            meta["refusal_present"] = refusal is not None
            meta["tool_calls_count"] = len(tool_calls) if isinstance(tool_calls, list) else (1 if tool_calls else 0)
            meta["function_call_present"] = function_call is not None
        except Exception:
            return meta
        return meta

    @staticmethod
    def _extract_raw_response(raw_response: Any) -> dict:
        """å°†åŸå§‹å“åº”è½¬æ¢ä¸ºå¯åºåˆ—åŒ–ç»“æ„ï¼ˆç”¨äº trace è®°å½•ï¼‰"""
        try:
            if hasattr(raw_response, "model_dump"):
                return raw_response.model_dump()
            if hasattr(raw_response, "dict"):
                return raw_response.dict()
            if isinstance(raw_response, dict):
                return raw_response
        except Exception:
            pass
        return {"raw": str(raw_response)}
    
    # =========================================================================
    # å…¼å®¹ Agent åŸºç±»æ¥å£ï¼ˆä½¿ç”¨ HistoryManagerï¼‰
    # =========================================================================
    
    def add_message(self, message: Message):
        """å…¼å®¹æ—§æ¥å£ï¼šæ·»åŠ æ¶ˆæ¯åˆ°å†å²"""
        if message.role == "user":
            self.history_manager.append_user(message.content, message.metadata)
        elif message.role == "assistant":
            self.history_manager.append_assistant(message.content, message.metadata)
        elif message.role == "tool":
            # æ³¨æ„ï¼šæ—§æ¥å£æ²¡æœ‰ tool_nameï¼Œä½¿ç”¨ metadata ä¸­çš„å€¼
            tool_name = (message.metadata or {}).get("tool_name", "unknown")
            self.history_manager.append_tool(tool_name, message.content, message.metadata)
        elif message.role == "summary":
            self.history_manager.append_summary(message.content)
    
    def clear_history(self):
        """å…¼å®¹æ—§æ¥å£ï¼šæ¸…ç©ºå†å²"""
        self.history_manager.clear()
    
    def get_history(self) -> List[Message]:
        """å…¼å®¹æ—§æ¥å£ï¼šè·å–å†å²"""
        return self.history_manager.get_messages()
