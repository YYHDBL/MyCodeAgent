# 面试经验贴（口语版）

下面是这次面试里，面试官常问的问题，以及我经过思考后更“成熟”的回答。内容不一定完全对应我当前实现，更像是面试场景下的最优表达。回答保持口语化，但逻辑清晰，必要时给小例子。

1、问题：为什么选择做 CLI 而不是 IDE 插件？
回答：我先选 CLI 是为了“快验证”和“可控”。CLI 用 Python 很快搭起来，调试简单，所有输出、日志、工具调用都能直接看到。插件体验更好，但要适配 IDE API、UI 框架、版本兼容，成本高。先用 CLI 把核心循环跑通，等逻辑稳定再考虑插件化，这样更稳。

2、问题：不同模型（Claude/DeepSeek/GPT）工具调用格式不一样，你怎么处理？
回答：主循环和模型层解耦，模型层走统一适配。工具调用尽量用“最小公约数”格式，比如 `Action: Tool[JSON]`，再加一层兼容解析（OpenAI tool_calls / function_call 也能兜住）。换模型时，一般只改配置和 prompt，不动核心循环。

3、问题：如果 MCP Server 挂了或返回脏数据，会崩吗？
回答：不会崩，最低标准是“失败可控”：异常要转成明确的工具错误，模型知道“这次失败了”，不会拿脏数据继续推理。更进一步是加轻量熔断，连续失败 N 次就临时禁用这个工具，避免一直浪费 token。

4、问题：大项目/全库理解怎么做？会不会把 token 撑爆？
回答：不会全量读。一般先看目录结构，再找入口文件、配置、README；需要定位功能时用 Grep 精准搜。复杂项目我会拆成子任务按模块读，最后做结构化总结。RAG 可以做，但 MVP 用“主动探索 + 分段总结”就够，先解决效率问题。

5、问题：Edit/Write 修改安全怎么保证？有没有人类确认？
回答：理想做法是“默认 dry_run + 人类确认”。MVP 里至少要有沙箱限制、路径校验、高危命令拦截，比如禁止 `rm -rf /`、`sudo`。生产级还要有确认门：高风险操作必须人工确认，避免 LLM 一脚踩雷。

6、问题：如果 Agent 卡住或死循环，怎么处理？
回答：最基础是 `max_steps`，防止无限循环。更实用的是“重复失败检测”：比如连续 3 次调用同一工具失败，就停止并向用户求助。这样能避免长时间卡住浪费 token。

7、问题：AskUser 怎么设计？是工具还是特殊状态？
回答：我更倾向做成工具。Agent 触发 `AskUser`，工具内部等待用户输入，输入后返回结果，主循环继续。这样不用做复杂的暂停/恢复状态机，代码更简单，也更贴近“工具调用”的心智模型。

8、问题：Trace 回放是“看日志”还是“可复现执行”？
回答：理想是“可复现执行”，但 MVP 先做到“完整日志”。后面可以做 deterministic replay：用 trace 里记录的 LLM 响应去 mock，再跑一遍主循环，就能 100% 复现路径。这个对排查复杂 bug 很有价值。

9、问题：会话中断后能恢复吗？
回答：MVP 可以先做 JSONL 追加写日志，至少能回看发生了什么；更进一步是恢复 history + todo 状态，实现断点续跑。比如中途退出，下次启动能接着走，这个是稳定性增强项。

10、问题：非确定性怎么测试？用 VCR 吗？
回答：CI 里走 mock，保证确定性；VCR 只录少量冒烟用例。因为 prompt 稍微改一个标点，录制就会失效，所以不能指望它覆盖所有回归。我的策略是：关键逻辑靠单测，效果评估靠手动或小规模回放。

11、问题：工具输出太长怎么办？
回答：统一截断，并明确告诉模型“这是截断输出”。必要时把完整内容落盘，并提示模型去 Read 或继续查。关键是让模型知道信息不完整，避免幻觉。

12、问题：SubAgent 怎么共享上下文？
回答：通常用独立会话，只传任务描述，结果回主 Agent 做摘要。这样 token 可控、职责清晰，不干扰主上下文。需要更多细节再传一段压缩摘要即可，避免全量共享。

13、问题：如果需要跑长命令（npm install / pytest），用户体验怎么办？
回答：MVP 可以先同步等待 + 超时兜底，保证不会无限卡住。更好的体验是流式输出，但那是后续优化，不是 MVP 必需。

14、问题：工具输出和上下文压缩怎么配合？
回答：先对工具输出做截断，再写入历史；历史太长再做结构化压缩。两个层次配合，既保留关键事实，也避免上下文爆炸。

---

## 补充：核心技术设计

### 15、问题：为什么用 Message List 模式而不是 Scratchpad 拼接？
回答：这是一个关键设计决策。传统 ReAct 会把 Thought/Action/Observation 拼成一个长文本（scratchpad），交给 LLM。但这有几个问题：一是格式混乱，LLM 容易"看走眼"；二是无法区分系统消息和历史对话；三是和 Chat API 的 messages 格式不匹配。

Message List 模式直接用标准的 Chat Messages 格式：
```
[
  {"role": "system", "content": "..."},
  {"role": "user", "content": "用户问题"},
  {"role": "assistant", "content": "Thought: ... Action: Tool[args]"},
  {"role": "tool", "content": "{工具响应JSON}"},
  ...
]
```

好处是：格式统一、L1/L2 系统提示清晰、历史管理方便、兼容所有 Chat API。唯一的代价是要自己维护历史压缩逻辑，但这比让 LLM 在混乱文本里找信息要靠谱。

### 16、问题：Skills 怎么管理？100 个 Skills 会不会把上下文撑爆？
回答：这是一个经典问题。我的做法是"描述列表 + 按需加载"：
- 只把 Skills 的 `name` 和 `description`（一行）注入 System Prompt
- LLM 决定需要哪个 Skill 后，调用 `Skill[name]` 工具
- 这时才加载完整的 Skill 内容

100 个 Skills 的描述列表大概 5K-10K token，完全可控。如果更多，可以考虑：
1. 按分类加载（只加载当前任务相关的类别）
2. 用关键词匹配预过滤
3. 或者用轻量 Embedding 做检索

但 RAG 对短描述效果不一定好，反而增加了复杂度。先把"分类 + 描述优化"做到极致，比直接上向量库更实用。

### 17、问题：安全隔离怎么做？直接跑在宿主机 Shell 吗？
回答：坦白说，当前 MVP 是"软隔离"——命令黑名单 + 工作目录沙箱。这不够安全，只是学习项目的权宜之计。

生产级应该用 OS 级别的沙箱：
- **Linux**: 用 `bwrap`（bubblewrap），`--ro-bind /usr /usr --bind $PROJECT $PROJECT --unshare-all`
- **macOS**: 用 `sandbox-exec` + `.sb` 配置文件（基于 Seatbelt）
- **敏感路径**: 过滤 `~/.ssh`、`~/.aws`、`/etc/passwd` 等

关键是：不要信任 LLM 生成的命令。哪怕有黑名单，也要有容器/沙箱兜底。

### 18、问题：为什么用纯文本解析工具调用，而不是 Function Calling API？
回答：这是一个权衡。Function Calling 更"正规"，但：
1. 不同模型的格式不统一（OpenAI `tool_calls` vs Claude `tool_use`）
2. 某些模型干脆不支持
3. 依赖模型输出结构化 JSON，反而更容易出错

我用的是 `Action: Tool[JSON]` 文本格式 + 正则解析。好处是：
- 所有模型都能稳定输出
- 格式可控，调试简单
- 不依赖特定 API

缺点是 LLM 可能偶尔不按格式输出，但这可以通过 few-shot examples 和重试机制解决。对于一个学习项目来说，通用性比"正统性"更重要。

---

## 项目亮点总结

### 技术亮点
1. **Message List 上下文工程**：标准化格式，兼容所有 Chat API
2. **统一工具协议**：status/data/text/error/stats/context 七字段，结构化且可扩展
3. **乐观锁机制**：Write/Edit 工具自动注入 mtime/size 校验，防止并发覆盖
4. **分层压缩策略**：工具输出截断 + 历史结构化压缩，支持长链路任务
5. **SubAgent 隔离**：独立会话 + 只读工具，避免递归和状态污染

### 当前不足
1. **安全隔离缺失**：需要引入 bwrap/sandbox-exec
2. **人类确认机制**：高危操作应要求用户确认
3. **Trace 回放**：目前只能看日志，不能 deterministic replay
4. **死循环检测**：只有 max_steps，没有重复模式检测

### 未来规划
短期（P0）：
- AskUser 工具（解决"缺信息就卡住"）
- MCP 错误分级（帮助 LLM 理解失败原因）
- 轻量熔断（连续失败禁用工具）
- Trace 脱敏（保护敏感信息）

中期（P1）：
- 沙箱隔离（bwrap/sandbox-exec）
- 死循环检测（重复模式识别）
- AskUser 人类确认（高危操作确认门）

长期（P2）：
- Skills RAG 检索（支持大量 Skills）
- Trace 回放（deterministic replay）
- 会话恢复（断点续跑）
