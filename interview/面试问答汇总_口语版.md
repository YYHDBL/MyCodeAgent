# 面试问答汇总（口语版 · 融合版）

> 说明：本文件融合了 `interview_experience.md`、`interview_summary.md`、`面试复盘-Agent项目技术面试.md`、`面试总结_MyCodeAgent项目.md` 的内容。
> 只保留**不重复**的问题，回答用口语化表达，尽量像真实面试现场。

---

## A. 项目定位与总体设计

**Q1：先用一句话介绍下这个项目？**
**Ans：**这是一个面向学习与实验的本地代码 Agent 框架，强调“可追溯、可验证、可扩展”。核心是 ReAct 循环 + 统一工具协议 + 上下文工程 + 子代理机制。

**Q2：你为什么做 CLI，而不是 IDE 插件？**
**Ans：**我先做 CLI 是为了“快验证 + 可控”。CLI 用 Python 很快搭起来，调试也简单，日志、工具输出都能直接看到。插件体验更好，但要适配 IDE API、UI 和版本兼容，成本太高。先把核心链路跑通再考虑插件化更稳。

**Q3：你说“类 Claude Code”，和 Claude Code / OpenDevin 的核心差异是什么？**
**Ans：**我走的是“小而可控、协议驱动、可追溯”的路线，不追求全自动化。更像是实验场而不是完整产品环境。它们更偏“产品化 + 一站式体验”，我更强调工程可控性和可复现。

---

## B. ReAct 循环与主流程

**Q4：ReAct 循环具体怎么跑？LLM 怎么知道该思考还是调工具？**
**Ans：**我用“显式工具调用”。流程是：拼 system prompt + 工具提示词 + history → 调 LLM → 解析 tool_calls → 执行工具 → 把结果写进 history → 下一轮。LLM 会看到工具 schema 和明确的工具提示词，所以知道什么时候该调用工具。空响应会补提示重试一次，防止模型“无话可说”。

**Q5：为什么用 Message List，而不是 Scratchpad 拼接？**
**Ans：**Scratchpad 把 Thought/Action/Observation 拼在一段长文本里，容易混乱、也不好兼容 Chat API。Message List 是标准格式：system / user / assistant / tool，结构清晰、历史管理容易，也更适配 function calling。代价是我要自己做历史压缩，但可控性更强。

**Q6：为什么选 Function Calling，而不是 Action 文本解析？**
**Ans：**稳定性和一致性。Function calling 是结构化协议，能强校验，避免 Action 文本被污染或解析失败。只要模型支持 tool_calls，主循环就能直接吃结构化参数，整体可靠性高很多。

---

## C. 工具系统与容错

**Q7：工具注册机制怎么设计？输入输出格式是什么样？**
**Ans：**所有工具继承统一 `Tool` 基类，输入用 schema 描述，输出统一成标准信封：`status/data/text/stats/context/error`。这样 Agent 不用猜“工具成功没”，像读 API 响应一样读状态。

**Q8：工具调用失败怎么处理？会自动重试吗？**
**Ans：**不自动重试。工具出错就返回 `status=error` + `ErrorCode`，比如 `NOT_FOUND/INVALID_PARAM/CONFLICT`。主 Agent 把错误结果写进历史，模型看到原因会修正下一步。只有“空响应”会补提示重试一次。

**Q9：如果模型陷入死循环，比如不断 ls 同一个错误路径？**
**Ans：**有轻量熔断：同一工具连续失败达到阈值（默认 3 次）会临时禁用，返回 `CIRCUIT_OPEN`，并把禁用列表写进工具提示。再加 max_steps 限制，避免无限循环。

**Q10：为什么不做并发？感觉并发能快很多？**
**Ans：**我刻意选串行。ReAct 是“观察-行动-再观察”，顺序本身是推理链的一部分。并发会引入竞态、历史顺序混乱，难追溯。写操作还有副作用，串行能稳定住“读→改→写”。未来可以考虑“只读并发池”，但写操作依然串行。

**Q11：并发读写冲突怎么避免？**
**Ans：**我用乐观锁：Read 返回 `file_mtime_ms` 和 `file_size_bytes`，Edit/Write 必须带这两个参数，否则报错；如果文件变了就返回 `CONFLICT`，强制 re-read。这样避免读旧写新。

**Q12：Edit 和 MultiEdit 怎么让模型选对？**
**Ans：**提示词里明确规则：Edit 只做“单点唯一替换”；MultiEdit 用于“同一文件多处独立修改、原子提交”。并强调“不要依赖中间状态、不要重叠编辑”。

**Q13：工具输出太长怎么办？**
**Ans：**统一截断：超行数/字节阈值就截断，把完整输出写入 `tool-output/`，历史只保留 preview + full_output_path。模型知道是截断的，会继续 Read 或按路径查。

**Q14：工具输出截断和上下文压缩怎么配合？**
**Ans：**先截断工具输出，再写入历史；历史太长再做结构化压缩。两个层次配合，既保留关键事实，又避免上下文爆炸。

---

## D. 上下文工程与稳定性

**Q15：上下文压缩什么时候触发？**
**Ans：**估算 token >= `context_window * compression_threshold`（默认 0.8），且轮次够多（默认保留 10 轮），避免刚积累一点就压。

**Q16：摘要怎么生成？为什么会超时？**
**Ans：**摘要用 LLM 生成，超时（默认 120s）就降级成硬截断。120s 是折中，太短失败多、太长拖慢链路。超时直接回退“只保留最近 N 轮”，不让流程卡住。

**Q17：token 估算用字符数/3太粗糙，怎么补救？**
**Ans：**这只是预警阈值，不是精算。阈值保守（0.8），再加压缩降级。未来可以接 tiktoken，但当前优先可控性。

**Q18：长链路怎么避免漂移和遗忘？**
**Ans：**主要靠三件事：历史压缩（保留关键事实）、工具输出截断（避免信息淹没）、熔断（防重复失败）。此外 trace 可以定位漂移根因，比如摘要丢了关键路径。

---

## E. SubAgent 与协作

**Q19：SubAgent 怎么实现？独立进程吗？**
**Ans：**不是独立进程，是同进程独立会话。Task 工具会创建一个 SubagentRunner，内部有独立 messages，逻辑隔离但不引入进程复杂度。

**Q20：SubAgent 权限怎么隔离？**
**Ans：**只读白名单（LS/Read/Grep/Glob/TodoWrite），拒绝 Write/Edit/Task/Bash。子代理只产出分析和建议，父代理执行写操作。

**Q21：如果 SubAgent 需要写文件怎么办？**
**Ans：**走 A：SubAgent 返回“需要写什么文件、改动内容”，父 Agent 执行真正的 Write/Edit。子代理不落盘，保证安全。

**Q22：多个 SubAgent 协作怎么传递结果？冲突怎么办？**
**Ans：**通过主 Agent 中转，子代理之间不直接通信。冲突时主 Agent 会要求补证据（路径/行号），或让 plan 重新制定基于证据的方案。

**Q23：SubAgent 能并行吗？**
**Ans：**当前不并行，原因是可追溯性优先。未来可以做“只读并发池”，但写操作仍串行。

---

## F. MCP 集成

**Q24：MCP 工具怎么注册？schema 怎么适配？**
**Ans：**启动时 `list_tools`，工具名做清洗+去重，inputSchema 映射为本地 ToolParameter。调用时适配器把 MCP 返回值包装成统一协议。

**Q25：MCP 超时或服务不可用怎么处理？**
**Ans：**统一返回 MCP_* 错误码（超时/网络/解析/执行）。主流程继续跑，MCP 是外挂，失败要可降级，不影响核心工具链。

---

## G. Skills 系统

**Q26：Skills 和工具有什么区别？**
**Ans：**Skill 是“提示词模板”，工具是“执行动作”。Skill 工具只负责加载 `SKILL.md` 并展开 `$ARGUMENTS`，然后交给 LLM 走正常 ReAct。

**Q27：Skill 执行中途需要读文件怎么办？**
**Ans：**Skill 不是状态机，只是一条增强提示。模型随时可以调用 Read/Grep 等工具补信息，和普通任务一样。

**Q28：Skills 很多会不会把上下文撑爆？**
**Ans：**我只把 Skills 的 name/description 注入 system prompt，真正需要时再用 Skill 工具加载全文。100 个技能也能控在几千 token 内。

---

## H. 可观测性与 Trace

**Q29：trace 是怎么串起来的？有标准格式吗？**
**Ans：**三层 ID：session_id（会话）、step（轮次）、tool_call_id（工具）。所有事件写 JSONL，另生成 HTML 方便回放审计。目前不是 OpenTelemetry，但预留扩展。

**Q30：trace 是“看日志”还是“可复现执行”？**
**Ans：**目前先做到完整日志回放。理想是 deterministic replay：用 trace 里的 LLM 响应去 mock，再跑一遍主循环，能 100% 复现路径。

**Q31：可观测性和性能怎么平衡？**
**Ans：**trace 可通过环境变量开关；HTML 里做了截断避免日志爆炸；原始响应是否记录可选。优先保证排障能力，性能开销可控。

---

## I. 测试与稳定性

**Q32：Agent 怎么测试？LLM 不确定性怎么处理？**
**Ans：**主要测确定性组件：工具协议、错误码、截断逻辑、乐观锁、熔断。LLM 输出不做硬断言。回归更多靠 trace 回放和小规模人工验证。

**Q33：用 VCR 录制测试可行吗？**
**Ans：**只适合少量冒烟用例。因为 prompt 改一点就会失效，不适合做大规模回归。

**Q34：会话中断后能恢复吗？**
**Ans：**MVP 先做 JSONL 日志回看；更进一步是保存 history + todo 状态，支持断点续跑。这个在 roadmap 里。

---

## J. 安全与执行环境

**Q35：你怎么保证 Edit/Write 安全？有没有人类确认？**
**Ans：**MVP 先做路径沙箱 + 黑名单（禁止 sudo、rm -rf 等）。理想方案是默认 dry_run + 人工确认，高风险操作必须确认。

**Q36：安全隔离怎么做？直接跑宿主机 Shell 吗？**
**Ans：**当前是软隔离（黑名单 + 工作目录沙箱），不够安全。生产级应该用 OS 沙箱：Linux 用 bwrap，macOS 用 sandbox-exec。敏感路径（~/.ssh 等）必须隔离。

**Q37：长命令（比如 pytest/npm install）用户体验怎么办？**
**Ans：**MVP 先同步等待 + 超时兜底，保证不会无限卡住。更好的体验是流式输出，这是后续优化方向。

---

## K. 产品/体验与策略

**Q38：不同模型 tool_calls 格式不一致，你怎么兼容？**
**Ans：**主循环和模型层解耦，统一走 function calling 的结构，模型只要能输出 tool_calls 就行。更换模型时通常只改 provider 配置和提示词。

**Q39：大项目/全库理解怎么做，避免 token 撑爆？**
**Ans：**先看目录结构，找入口文件/配置/README，再用 Grep 精准搜索。复杂项目拆成子任务分段读，最后做结构化总结。先用“主动探索 + 分段总结”，RAG 不是 MVP 必需。

**Q40：AskUser 怎么设计？是工具还是特殊状态？**
**Ans：**我更倾向做成工具。触发 AskUser 后工具等待输入，输入再返回结果，主循环继续。这样不需要复杂暂停/恢复状态机。

**Q41：什么时候不该用 Agent？**
**Ans：**强一致性任务、可脚本化批量改动、低延迟实时场景，脚本或人工更稳。Agent 更适合探索性、半结构化的任务。

---

## L. 选型、技术债与未来方向

**Q42：为什么选 Python 而不是 TS？**
**Ans：**Python 迭代快、LLM 生态成熟，适合实验型项目；TS 类型安全、MCP 生态更好，适合产品化。目标偏实验，所以 Python 合理。

**Q43：最想重构的点？**
**Ans：**工具提示词组织方式、token 估算/溢出恢复机制、LLM 调用封装层。这些现在偏 MVP，后续要工程化。

**Q44：性能瓶颈在哪？**
**Ans：**主要是 LLM 调用，其次 Summary 生成。工具执行不是最大头。

**Q45：最难排查的 bug 是啥？**
**Ans：**模型输出结构偶发异常，比如空 content 或缺 tool_call_id。修复靠 trace、空响应重试、补齐 tool_call_id。

**Q46：开发中最大的坑是什么？**
**Ans：**工具输出过大导致上下文爆炸。早期 grep/read 输出太长，模型注意力被淹没甚至解析失败。最后用“统一截断 + 落盘 + 历史压缩”解决，这是稳定性提升最大的改动。

**Q47：未来最想加的 3 个点？**
**Ans：**
1) 智能压缩 + 溢出自动恢复；
2) 只读并发池；
3) trace 可视化/标准化（向 OpenTelemetry 靠拢）。

**Q48：重新设计的话，一开始就会做什么？**
**Ans：**一开始就定工具协议、上 trace、做乐观锁。它们是“救命线”，越早越省坑。

---

# 具体排障故事（可直接口述）

**故事 1：工具输出截断 + Summary 丢关键信息**
- 现象：长链路任务里模型反复 Grep，结果每次被截断，连续 5 轮没有进展。
- 定位：看 trace，发现 summary 丢了目标文件路径，模型只能盲搜。
- 根因：summary prompt 没强调“必须保留文件路径和关键符号名”。
- 修复：调整 summary prompt，增加“保留路径/命名实体”要求；截断提示里加“如何继续 Read”。
- 结果：重复失败从 5 次降到 1 次以内，任务完成率明显提升。

**故事 2：模型输出结构异常导致流程卡住**
- 现象：偶发空 content 且无 tool_calls，主循环卡死。
- 定位：trace 显示 raw response 空，finish_reason 异常。
- 修复：空响应重试一次；强制补齐 tool_call_id。
- 结果：空响应失败率显著下降，流程更稳定。

---

# 带数据的回答模板（可替换为真实数字）

**模板 1：稳定性类**
- “我们把工具调用成功率做到 **XX%**，解析失败率压到 **YY%**，熔断触发频率大概 **每 ZZ 轮 1 次**。”

**模板 2：性能占比类**
- “从 trace 看，LLM 调用占总耗时约 **XX%**，工具执行 **YY%**，上下文构建/压缩 **ZZ%**。优化优先级就是 LLM > Summary > 工具。”

**模板 3：上下文成本类**
- “平均每轮消耗 **X.XK tokens**，压缩后历史保留约 **YY%**，工具输出截断后上下文体积下降 **ZZ%**。”

---

# 复习提示（给自己看的）

- 面试更看重“真实排障故事 + 数据”，不是“概念背诵”。
- 回答顺序建议：结论 → 原因 → 取舍 → 结果。
- 简历表述避免虚假并发，实现就写“预留并发架构”。
