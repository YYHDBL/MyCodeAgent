# MyCodeAgent 项目技术面试复盘

> 面试类型：电话技术面试
> 面试官角色：类 Claude Code/Kode-cli 项目开发者
> 面试者：本项目作者
> 面试时间：2026-01-21

---

## 一、面试背景

### 项目概述
MyCodeAgent 是一款基于终端的智能编程助手（类似 Claude Code），技术栈为 Python，基于 ReAct 范式实现：
- 自主代码库探索与修改
- MCP（Model Context Protocol）集成
- 上下文工程与历史压缩
- Agent Skills 系统
- 全链路可观测性

### 面试考察维度
1. 核心架构理解（ReAct 循环、工具系统）
2. 工程实践（容错、并发、锁机制）
3. 上下文管理（压缩、token 估算）
4. 可观测性设计（trace、日志）
5. 系统集成（MCP、SubAgent、Skills）
6. 技术决策思路（trade-off 分析）
7. 实战经验（踩坑与解决）

---

## 二、面试问题与回答记录

### 第一轮面试（5 题）

#### Q1：工具系统为什么选择异步生成器模式？

**面试官意图**：考察对工具系统设计模式的理解，以及对异步/流式输出的思考。

**你的回答**：
- 项目使用 Python，没有用 JS 的 Promise 或异步生成器驱动工具流式输出
- 工具调用在 ReAct 步内是**串行执行**，每次返回完整的结构化结果
- 真正用异步的是 MCP 客户端（asyncio），但对主流程暴露同步封装
- 核心逻辑更稳更可控

**设计理由**：
1. 可追溯和可复现 - 工具结果是"标准信封"，便于写入历史、做 trace、做压缩
2. 串行执行让每一步都可解释，避免并发时的状态交错
3. 核心 Agent 逻辑更稳定

**评价**：
- ✅ 清晰说明技术栈差异（Python vs JS/TS）
- ✅ 设计决策有明确理由（可追溯性优先）
- ✅ 没有盲目追求"时髦"技术

**可追问点**：
- 工具执行时间长时（如编译命令跑 2 分钟）如何处理？

---

#### Q2：ReAct 循环中如何处理工具调用失败？

**面试官意图**：考察容错机制设计和错误处理策略。

**你的回答**：
- 工具出错返回 `status=error`，带 `error.code`（如 NOT_FOUND、INVALID_PARAM）和明确提示
- 主 Agent 将错误结果作为 tool message 写入历史，让 LLM 看到"失败原因"
- **不自动重试**（除非"模型返回空响应"会补提示重试一次）
- 举例：`ListFiles` 路径不存在 → 返回 NOT_FOUND → LLM 看到错误 → 下一轮修正路径

**设计原则**：
- "错误回传给模型 → 模型纠正"，而非框架盲目重试

**评价**：
- ✅ 统一的错误协议设计
- ✅ 让 LLM 自主纠错符合 ReAct 理念
- ✅ 没有过度设计自动重试逻辑

**可追问点**：
- 是否遇到过 LLM 陷入错误循环的情况？

---

#### Q3：上下文压缩如何触发？压缩后信息丢失怎么办？

**面试官意图**：考察上下文管理的核心技术难点。

**你的回答**：

**触发机制**（阈值 + 轮次保留）：
- token 估算：字符数/3 粗略估算
- 与 `context_window * compression_threshold` 比较
- 要求消息数足够 + 保留 `min_retain_rounds` 轮原始对话

**压缩方式**（Summary + 保留最近轮次）：
- 旧消息交给 Summary 生成器
- Summary 超时（默认 120s）降级成硬截断

**信息丢失应对**：
- "问第 15 行怎么办" → 读文件是事实来源，Agent 会重新调用 Read 工具
- 工具输出截断会把完整结果落盘到 `tool-output/`
- 提示词要求"信息不确定必须读文件"
- 工具返回明确提示"被截断请继续读"

**风险承认**：
- 存在"压缩后瞎编"风险，通过提示工程缓解

**评价**：
- ✅ 多层降级策略（LLM 摘要 → 硬截断）
- ✅ "完整结果落盘"是关键设计
- ⚠️ token 估算较粗糙

**可追问点**：
- 字符数/3 的误差有多大？是否遇到过 API 报 context_length_exceeded？

---

#### Q4：并发工具执行的竞态条件如何处理？

**面试官意图**：考察并发编程能力和对一致性的理解。

**你的回答**：
- **当前没有实现真正并发执行**，工具调用是串行的
- 通过乐观锁防止"读后被改"：
  - `Read` 返回 `file_mtime_ms` 和 `file_size_bytes`
  - `Edit/Write` 需带这两个参数，否则 `INVALID_PARAM`
  - 文件已变则返回 `CONFLICT`，强制重读

**没有实现 `isConcurrencySafe` 标记机制**

**评价**：
- ✅ 乐观锁设计合理
- ✅ 诚实说明未实现并发
- ⚠️ 简历中"并发"相关表述可能有歧义

**可追问点**：
- 为什么选择串行而非并发？是否考虑过只读工具并发？

---

#### Q5：MCP 集成如何映射工具？如何处理超时/故障？

**面试官意图**：考察系统集成能力和兼容性处理经验。

**你的回答**：

**适配层设计**：
- 用 MCP client 拉 `list_tools`
- 工具名处理：命名空间 + 清洗 + 去重
- MCP 的 `inputSchema` 映射到本地 `ToolParameter`
- 调用时用适配器转成内部标准协议

**兼容性问题**：
1. MCP 工具 schema 不完整/不规范 → 本地参数校验放宽
2. MCP 异常/超时 → 统一返回 `MCP_TIMEOUT` / `MCP_NETWORK_ERROR`

**降级策略**：
- MCP server 起不来：注册失败被捕获并记录，不影响核心工具
- 调用失败：转 error 结果，Agent 继续而非崩溃
- 核心原则：优先保证"核心工具链可用"

**评价**：
- ✅ 适配器模式应用得当
- ✅ 降级策略清晰
- ✅ 优先保证核心功能的设计哲学正确

---

### 第二轮追问（6 题）

#### Q6：为什么选择串行而非并发？

**你的回答**：
1. **可追溯性和确定性优先** - ReAct 是"观察-行动-再观察"，顺序是模型推理链的一部分
2. **文件类工具有副作用** - 并发会让冲突变复杂，串行能稳定住"读→改→写"链条
3. **工程复杂度** - 并发需引入 asyncio 适配层或线程池，可观测性更难

**未来规划**：
- 架构上不排斥未来加"只读并发池"
- 出于工程风险和复杂度控制暂未实现

**评价**：
- ✅ 理由充分，trade-off 清晰
- ✅ 没有盲目追求性能
- ✅ 主动提及未来优化方向

---

#### Q7：字符数/3 估算的误差如何处理？

**你的回答**：
- 承认是**粗估**，用途是"是否接近上限"的预警，非精确计数

**补救措施**：
1. 阈值保守（默认 0.8），避免贴上限走
2. 最少轮次保留，避免频繁压缩
3. **触发 `context_length_exceeded` 时目前 API 异常直接抛出，不会自动修复**

**承认不足**：
- 理想方案是捕获异常后强制压缩再重试
- 目前更多是手动调参处理

**评价**：
- ✅ 诚实承认不足
- ✅ 保守阈值是合理工程实践
- ⚠️ 自动恢复机制是技术债

---

#### Q8：Summary 120 秒超时如何确定？

**你的回答**：
- **工程折中**：太短导致摘要大量失败，太长拖慢链路
- 做成可配置（`SUMMARY_TIMEOUT`）
- 超时即降级为"硬截断 + 保留最近 N 轮"

**轻量方案**：
- "完全不用 LLM 摘要"已经是降级路径的一部分
- 实际策略：先尝试 LLM 摘要，失败回到轻量方案

**评价**：
- ✅ 可配置化设计
- ✅ 多层降级策略

---

#### Q9：trace 的唯一 ID 如何生成？如何串联？

**你的回答**：

**三层 ID 结构**：
- 会话级：`session_id`，每个 session 唯一
- 步骤级：ReAct loop 的 `step` 号
- 工具级：`tool_call_id`，模型没给就用 uuid 生成

**串联方式**：
- Trace 记录 `model_output → tool_call → tool_result` 在同一 step
- 所有事件写到同一 JSONL

**格式选择**：
- 自定义 JSONL 格式 + HTML 可视化
- **未使用 OpenTelemetry**，原因是工程复杂度和依赖成本
- 追求"先跑通、可调试"

**评价**：
- ✅ 三层 ID 设计清晰
- ✅ 自定义格式在 MVP 阶段合理
- ⚠️ 标准化是未来优化方向

---

#### Q10：SubAgent 如何实现？权限如何隔离？

**你的回答**：
- **非独立进程**，同进程独立会话
- `Task` 工具创建 `SubagentRunner`，内部有独立 `messages` 列表
- 逻辑隔离，不引入进程级复杂度

**权限隔离**：
- 过滤机制：deny `Task/Write/Edit/MultiEdit/Bash`
- 只允许 `LS/Glob/Grep/Read/TodoWrite`
- SubAgent 做"分析+建议"，父 Agent 执行真正的写操作

**评价**：
- ✅ 权限过滤设计合理
- ✅ 同进程实现降低复杂度
- ✅ "分析+建议"模式符合职责分离

---

#### Q11：Skills 系统与工具的区别？

**你的回答**：
- Skills 本质是**可复用的提示词模板**，非可执行工具
- 以 `SKILL.md` 存储，带 YAML frontmatter + `$ARGUMENTS` 占位
- Skill 工具只负责"加载+展开"，最终给 LLM 读

**区别**：
- 工具是"执行动作"
- Skill 是"给模型一套稳定的工作流程/检查清单"

**举例**：
- "写测试" skill 定义"先定位测试目录 → 再写用例结构 → 再运行 pytest"的步骤
- 强调过程一致性

**评价**：
- ✅ 概念清晰
- ✅ 没有过度设计
- ✅ "提示词模板"是简单有效的方案

---

### 第三轮深入（3 题）

#### Q12：SubAgent 没写权限，如何完成任务？

**你的回答**：
- SubAgent 只做"分析+建议"
- 在结果里说明"需要新建/修改哪些文件、改动内容是什么"
- 父 Agent 负责真正的 `Write/Edit`
- 刻意的权限隔离：子代理不落盘，父代理审核后执行

**评价**：
- ✅ 职责分离设计优秀
- ✅ 父子 Agent 协作模式清晰

---

#### Q13：Skills 执行中途需要交互怎么办？

**你的回答**：
- Skill 本质是"增强版 UserMessage"
- Skill 工具读取 `SKILL.md` 并替换 `$ARGUMENTS`，丢给模型
- 之后是正常 ReAct：模型随时可调用 `Read/Grep` 等工具
- **没有"暂停/继续"的状态机**，就是"提示词模板 + 常规循环"

**评价**：
- ✅ 设计简单有效
- ✅ 没有过度设计状态机

---

#### Q14：系统提示词如何动态构建？如何缓存？

**你的回答**：

**动态拼装内容**：
- L1 系统提示
- 工具提示词
- （可选）MCP 工具提示
- CODE_LAW

**缓存机制**：
- `CODE_LAW` 有 `mtime` 缓存，不变就不重读
- MCP/Skills 提示更新时清空缓存
- Tool 的 function calling schema 每次调用都带，但不在文本里

**按需加载**：
- **没有默认注入** `CLAUDE.md` / git status / 目录结构
- 这些按需用工具拿，避免占 token

**评价**：
- ✅ 缓存策略合理
- ✅ 按需加载避免 token 浪费
- ✅ 工程化思维到位

---

#### Q15：LLM 陷入死循环怎么办？

**你的回答**：

**容错机制**：
1. **工具熔断**：同一工具连续失败达阈值（默认 3 次）临时禁用（`CIRCUIT_OPEN`）
2. **最大步数限制**：防止无穷循环
3. 熔断后写进工具提示，阻止模型继续重复调用

**未实现**：
- 复杂循环检测（如"相同参数重复"）
- 主要靠熔断 + 终止步数

**评价**：
- ✅ 熔断模式是工业界成熟方案
- ✅ 最大步数限制是兜底保障
- ✅ 没有过度设计

---

#### Q16：开发过程中最大的坑是什么？

**你的回答**：
- **工具输出过大导致上下文爆炸**
- 早期 `grep/read` 输出太长，模型注意力被淹没，甚至解析失败
- 最终方案：**统一截断 + 落盘 + 历史压缩**
  - 超限输出截断
  - 完整结果写到 `tool-output/`
  - 历史只保留摘要 + 最近轮次

**评价**：
- ✅ 这是真实的踩坑经验
- ✅ 解决方案完整且有效
- ✅ "稳定性提升最大的改动"体现数据驱动思维

---

### 第四轮收尾（3 题）

#### Q17：未来最想优化的 3 个点？

**你的回答**：

1. **智能压缩 + 溢出自动恢复**
   - 按重要度/引用频率/任务相关性保留
   - `context_length_exceeded` 后自动压缩再重试

2. **只读并发池**
   - `Read/Grep/Glob` 等纯读工具并行化
   - 减少探索阶段等待时间，不破坏写操作确定性

3. **更好的 trace 可视化**
   - 类似 LangSmith 的时间线 + 搜索 + 对比视图
   - 当前 JSONL + HTML 能用但不够可检索/可对比

**评价**：
- ✅ 优化方向明确且有优先级
- ✅ 兼顾性能（并发）、可靠性（压缩）、体验（可视化）
- ✅ 显示有产品思维

---

#### Q18：Python vs TypeScript，选型对吗？

**你的回答**：

**当时选 Python 是对的**：
- 项目是"实验性 + 算法/提示词驱动"
- Python 迭代速度快、AI/ML 生态好

**但羡慕 TS 的几点**：
1. **类型安全**：工具协议、schema、消息结构有类型会更早暴露错误
2. **MCP 生态**：Node/TS 对接 MCP 更顺滑
3. **工程化工具链**：lint/typecheck 约束更强

**结论**：
- **产品化 + 多人协作** → TS 更合适
- **快速实验 + 机制验证** → Python 合适

**评价**：
- ✅ 技术选型思考成熟
- ✅ 能分析不同场景的适用性
- ✅ 没有"语言崇拜"，理性分析

---

#### Q19：重新设计会一开始就做什么？

**你的回答**：

1. **工具协议（标准信封）** - 早点定，后续所有工具都能对齐
2. **trace 系统** - 原始响应和工具调用链路记录，是排坑的救命线
3. **乐观锁** - `Read → Edit` 一致性问题早点解决，减少隐性 bug

**评价**：
- ✅ 三点都是架构级设计，非实现细节
- ✅ 体现出"从 0 到 1"的经验总结
- ✅ 可观测性和数据一致性优先

---

## 三、简历优化建议

### 原简历表述问题
原简历："支持文件检索、编辑、Todo任务清单规划，SubAgent等内置工具与 MCP 扩展"

**问题**：未明确说明是否支持并发执行，可能造成歧义。

### 建议修改方案

#### 方案一：明确并发扩展能力
```
实现工具熔断与权限隔离机制，架构上预留只读工具并发执行能力（Read/Grep/Glob 并行化，
写操作串行保证一致性）
```

#### 方案二：更简洁版
```
设计工具权限隔离与熔断机制，支持只读工具并发池架构扩展
```

### 上下文工程部分优化
```
上下文工程：设计分层消息结构，实现统一工具输出截断与完整结果落盘机制，结合历史摘要
与容错降级，保障 200K 上下文窗口下长链路任务稳定性
```

### 可观测性部分优化
```
可观测性：建立全链路 trace（JSONL 格式）支持会话回放与问题定位，预留
OpenTelemetry 标准化扩展能力
```

---

## 四、技术亮点提炼（面试可讲的 Story）

### Story 1：工具输出截断问题
**背景**：早期 grep/read 输出过长，导致上下文爆炸、LLM 解析失败

**解决**：
- 统一截断机制 + 完整结果落盘到 `tool-output/`
- 历史只保留摘要 + 最近轮次
- 工具返回明确提示"被截断请继续读"

**结果**：稳定性提升最大的一次改动

---

### Story 2：乐观锁防止文件冲突
**背景**：Agent 多轮对话中可能出现"读后被改"的情况

**解决**：
- `Read` 返回 `file_mtime_ms` 和 `file_size_bytes`
- `Edit/Write` 需带这两个参数，否则拒绝
- 文件已变返回 `CONFLICT`，强制重读

**结果**：避免了隐性 bug，保证操作一致性

---

### Story 3：MCP 集成的降级策略
**背景**：MCP 服务器可能不稳定或超时

**解决**：
- MCP server 起不来：注册失败被捕获，不影响核心工具
- 调用失败：转 error 结果，Agent 继续而非崩溃
- 核心原则：优先保证"核心工具链可用"

**结果**：系统整体鲁棒性强

---

## 五、面试表现总结

### 优势

| 维度 | 评价 |
|------|------|
| **实战经验** | ✅ 所有问题都是真实踩过的坑，非纸上谈兵 |
| **设计思路** | ✅ 每个 trade-off 都有明确理由 |
| **工程化意识** | ✅ trace、熔断、协议标准化，体现工程思维 |
| **诚实度** | ✅ 承认不足（token 估算粗糙、无自动重试） |
| **架构能力** | ✅ 分层清晰、职责分离、降级策略完备 |
| **沟通表达** | ✅ 回答结构化，先结论再解释 |

### 可改进空间

| 问题 | 建议 |
|------|------|
| 并发执行未实现 | 简历中明确"预留扩展能力"，可聊方案但别吹已实现 |
| token 估算较粗糙 | 可引入 tiktoken 等库，算技术债 |
| 自动恢复机制 | context_length_exceeded 后的自动重试可补充 |
| trace 标准化 | 未来可考虑 OpenTelemetry，便于接入监控系统 |

### 面试通过度：✅ 建议 Pass

**理由**：
- 对项目有深入理解
- 设计决策合理且有思考
- 遇到过实际问题并解决
- 诚实且有工程化意识

**评级**：中高级工程师水平

---

## 六、后续准备建议

### 技术深度准备

1. **并发编程**：如果面试官深入问并发，准备好 asyncio/线程池的知识
2. **MCP 协议**：了解 MCP 的设计理念和标准用法
3. **LLM 调优**：准备好 prompt engineering 的经验案例
4. **分布式追踪**：了解 OpenTelemetry 的基本概念

### 项目亮点准备

选择 2-3 个最有技术含量的点，准备：
- 背景（什么问题）
- 方案（怎么解决）
- 结果（什么效果）
- 思考（如果重来会怎么做）

### 反问准备

准备好向面试官提问的问题：
- "你们的技术栈是什么？"
- "这个岗位的技术挑战是什么？"
- "团队的开发流程是怎样的？"

---

## 七、附录：关键技术概念速查

### ReAct 范式
- Reasoning + Acting
- 循环：思考 → 行动 → 观察 → 思考 ...
- 核心：让 LLM 能够推理并执行工具调用

### MCP (Model Context Protocol)
- Anthropic 提出的标准协议
- 用于 LLM 应用与外部服务/数据源交互
- 支持工具、资源、提示三种类型

### 熔断模式
- 来自《Release It!》的模式
- 连续失败达阈值后"开路"，暂停调用
- 一段时间后"半开"，尝试恢复

### 乐观锁
- 假设冲突不频繁，先读后写校验
- 比悲观锁性能更好
- 适合读多写少的场景

---

**文档生成时间**：2026-01-21
**面试复盘价值**：⭐⭐⭐⭐⭐

---

## 快速索引

| 话题 | 问题编号 |
|------|---------|
| 工具系统设计 | Q1, Q4, Q6, Q12 |
| 错误处理与容错 | Q2, Q15 |
| 上下文管理 | Q3, Q7, Q8, Q14 |
| 可观测性 | Q9, Q17 |
| MCP 集成 | Q5 |
| SubAgent | Q10, Q12 |
| Skills 系统 | Q11, Q13 |
| 技术选型 | Q18 |
| 架构设计 | Q19 |
| 实战经验 | Q16 |
